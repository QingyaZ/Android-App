{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9kuBTmZPLnB"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/yandex-research/rtdl-revisiting-models/blob/main/package/example.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "---\n",
        "\n",
        "**See also** [RTDL](https://github.com/yandex-research/rtdl)\n",
        "-- **other projects on tabular deep learning**.\n",
        "\n",
        "---\n",
        "\n",
        "- This notebook provides a usage example of the\n",
        "  [rtdl_revisiting_models](https://github.com/yandex-research/rtdl-revisiting-models)\n",
        "  package.\n",
        "- Hyperparameters are not tuned and may be suboptimal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsIIj9u0PLnD",
        "outputId": "e1999bd4-8fcb-4ba8-b420-bc224712099a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting delu==0.0.23\n",
            "  Downloading delu-0.0.23-py3-none-any.whl.metadata (805 bytes)\n",
            "Requirement already satisfied: numpy<2,>=1.18 in /usr/local/lib/python3.11/dist-packages (from delu==0.0.23) (1.26.4)\n",
            "Requirement already satisfied: torch<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from delu==0.0.23) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=1.8->delu==0.0.23)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->delu==0.0.23) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.8->delu==0.0.23) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.8->delu==0.0.23) (3.0.2)\n",
            "Downloading delu-0.0.23-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, delu\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed delu-0.0.23 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting rtdl_revisiting_models\n",
            "  Downloading rtdl_revisiting_models-0.0.2-py3-none-any.whl.metadata (888 bytes)\n",
            "Requirement already satisfied: torch<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from rtdl_revisiting_models) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.8->rtdl_revisiting_models) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.8->rtdl_revisiting_models) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.8->rtdl_revisiting_models) (3.0.2)\n",
            "Downloading rtdl_revisiting_models-0.0.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: rtdl_revisiting_models\n",
            "Successfully installed rtdl_revisiting_models-0.0.2\n"
          ]
        }
      ],
      "source": [
        "%pip install delu==0.0.23\n",
        "%pip install rtdl_revisiting_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRFzdozyPLnD",
        "outputId": "eb163076-1896-4f6e-b994-740130ea52e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ],
      "source": [
        "# ruff: noqa: E402\n",
        "import math\n",
        "import warnings\n",
        "from typing import Dict, Literal\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "import delu  # Deep Learning Utilities: https://github.com/Yura52/delu\n",
        "import numpy as np\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "from torch import Tensor\n",
        "from tqdm.std import tqdm\n",
        "\n",
        "warnings.resetwarnings()\n",
        "\n",
        "from rtdl_revisiting_models import MLP, ResNet, FTTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn6NIkjnPLnE",
        "outputId": "15c8b6d3-5644-4017-eccf-3e535ae1521b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Set random seeds in all libraries.\n",
        "delu.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1NeFsR_PLnE"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qJWH3SpbPLnE"
      },
      "outputs": [],
      "source": [
        "# >>> Dataset.\n",
        "TaskType = Literal[\"regression\", \"binclass\", \"multiclass\"]\n",
        "\n",
        "task_type: TaskType = \"regression\"\n",
        "n_classes = None\n",
        "dataset = sklearn.datasets.fetch_california_housing()\n",
        "print(dataset)\n",
        "X_cont: np.ndarray = dataset[\"data\"]\n",
        "Y: np.ndarray = dataset[\"target\"]\n",
        "\n",
        "# NOTE: uncomment to solve a classification task.\n",
        "# n_classes = 2\n",
        "# assert n_classes >= 2\n",
        "# task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
        "# X_cont, Y = sklearn.datasets.make_classification(\n",
        "#     n_samples=20000,\n",
        "#     n_features=8,\n",
        "#     n_classes=n_classes,\n",
        "#     n_informative=3,\n",
        "#     n_redundant=2,\n",
        "# )\n",
        "\n",
        "# >>> Continuous features.\n",
        "X_cont: np.ndarray = X_cont.astype(np.float32)\n",
        "n_cont_features = X_cont.shape[1]\n",
        "\n",
        "# >>> Categorical features.\n",
        "# NOTE: the above datasets do not have categorical features, but,\n",
        "# for the demonstration purposes, it is possible to generate them.\n",
        "cat_cardinalities = [\n",
        "    # NOTE: uncomment the two lines below to add two categorical features.\n",
        "    # 4,  # Allowed values: [0, 1, 2, 3].\n",
        "    # 7,  # Allowed values: [0, 1, 2, 3, 4, 5, 6].\n",
        "]\n",
        "X_cat = (\n",
        "    np.column_stack(\n",
        "        [np.random.randint(0, c, (len(X_cont),)) for c in cat_cardinalities]\n",
        "    )\n",
        "    if cat_cardinalities\n",
        "    else None\n",
        ")\n",
        "\n",
        "# >>> Labels.\n",
        "# Regression labels must be represented by float32.\n",
        "if task_type == \"regression\":\n",
        "    Y = Y.astype(np.float32)\n",
        "else:\n",
        "    assert n_classes is not None\n",
        "    Y = Y.astype(np.int64)\n",
        "    assert set(Y.tolist()) == set(\n",
        "        range(n_classes)\n",
        "    ), \"Classification labels must form the range [0, 1, ..., n_classes - 1]\"\n",
        "\n",
        "# >>> Split the dataset.\n",
        "all_idx = np.arange(len(Y))\n",
        "trainval_idx, test_idx = sklearn.model_selection.train_test_split(\n",
        "    all_idx, train_size=0.8\n",
        ")\n",
        "train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
        "    trainval_idx, train_size=0.8\n",
        ")\n",
        "data_numpy = {\n",
        "    \"train\": {\"x_cont\": X_cont[train_idx], \"y\": Y[train_idx]},\n",
        "    \"val\": {\"x_cont\": X_cont[val_idx], \"y\": Y[val_idx]},\n",
        "    \"test\": {\"x_cont\": X_cont[test_idx], \"y\": Y[test_idx]},\n",
        "}\n",
        "if X_cat is not None:\n",
        "    data_numpy[\"train\"][\"x_cat\"] = X_cat[train_idx]\n",
        "    data_numpy[\"val\"][\"x_cat\"] = X_cat[val_idx]\n",
        "    data_numpy[\"test\"][\"x_cat\"] = X_cat[test_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ2GSlxCPLnE"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V9hN-IdzPLnF"
      },
      "outputs": [],
      "source": [
        "# >>> Feature preprocessing.\n",
        "# NOTE\n",
        "# The choice between preprocessing strategies depends on a task and a model.\n",
        "\n",
        "# (A) Simple preprocessing strategy.\n",
        "# preprocessing = sklearn.preprocessing.StandardScaler().fit(\n",
        "#     data_numpy['train']['x_cont']\n",
        "# )\n",
        "\n",
        "# (B) Fancy preprocessing strategy.\n",
        "# The noise is added to improve the output of QuantileTransformer in some cases.\n",
        "X_cont_train_numpy = data_numpy[\"train\"][\"x_cont\"]\n",
        "noise = (\n",
        "    np.random.default_rng(0)\n",
        "    .normal(0.0, 1e-5, X_cont_train_numpy.shape)\n",
        "    .astype(X_cont_train_numpy.dtype)\n",
        ")\n",
        "preprocessing = sklearn.preprocessing.QuantileTransformer(\n",
        "    n_quantiles=max(min(len(train_idx) // 30, 1000), 10),\n",
        "    output_distribution=\"normal\",\n",
        "    subsample=10**9,\n",
        ").fit(X_cont_train_numpy + noise)\n",
        "del X_cont_train_numpy\n",
        "\n",
        "for part in data_numpy:\n",
        "    data_numpy[part][\"x_cont\"] = preprocessing.transform(data_numpy[part][\"x_cont\"])\n",
        "\n",
        "# >>> Label preprocessing.\n",
        "if task_type == \"regression\":\n",
        "    Y_mean = data_numpy[\"train\"][\"y\"].mean().item()\n",
        "    Y_std = data_numpy[\"train\"][\"y\"].std().item()\n",
        "    for part in data_numpy:\n",
        "        data_numpy[part][\"y\"] = (data_numpy[part][\"y\"] - Y_mean) / Y_std\n",
        "\n",
        "# >>> Convert data to tensors.\n",
        "data = {\n",
        "    part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
        "    for part in data_numpy\n",
        "}\n",
        "\n",
        "if task_type != \"multiclass\":\n",
        "    # Required by F.binary_cross_entropy_with_logits\n",
        "    for part in data:\n",
        "        data[part][\"y\"] = data[part][\"y\"].float()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYuVW1qvPLnF"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcAhDuI1PLnF",
        "outputId": "14c35bec-a428-4459-98f1-9eb15661bbdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        }
      ],
      "source": [
        "# The output size.\n",
        "d_out = n_classes if task_type == \"multiclass\" else 1\n",
        "\n",
        "# # NOTE: uncomment to train MLP\n",
        "# model = MLP(\n",
        "#     d_in=n_cont_features + sum(cat_cardinalities),\n",
        "#     d_out=d_out,\n",
        "#     n_blocks=2,\n",
        "#     d_block=384,\n",
        "#     dropout=0.1,\n",
        "# ).to(device)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "\n",
        "# # NOTE: uncomment to train ResNet\n",
        "# model = ResNet(\n",
        "#     d_in=n_cont_features + sum(cat_cardinalities),\n",
        "#     d_out=d_out,\n",
        "#     n_blocks=2,\n",
        "#     d_block=192,\n",
        "#     d_hidden=None,\n",
        "#     d_hidden_multiplier=2.0,\n",
        "#     dropout1=0.3,\n",
        "#     dropout2=0.0,\n",
        "# ).to(device)\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
        "\n",
        "model = FTTransformer(\n",
        "    n_cont_features=n_cont_features,\n",
        "    cat_cardinalities=cat_cardinalities,\n",
        "    d_out=d_out,\n",
        "    **FTTransformer.get_default_kwargs(),\n",
        ").to(device)\n",
        "optimizer = model.make_default_optimizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-phdRlcPLnF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXZk8MsGPLnF",
        "outputId": "b9a63b40-f614-49be-8a09-2b3696f8536f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score before training: -1.1242\n"
          ]
        }
      ],
      "source": [
        "def apply_model(batch: Dict[str, Tensor]) -> Tensor:\n",
        "    if isinstance(model, (MLP, ResNet)):\n",
        "        x_cat_ohe = (\n",
        "            [\n",
        "                F.one_hot(column, cardinality)\n",
        "                for column, cardinality in zip(batch[\"x_cat\"].T, cat_cardinalities)\n",
        "            ]\n",
        "            if \"x_cat\" in batch\n",
        "            else []\n",
        "        )\n",
        "        return model(torch.column_stack([batch[\"x_cont\"]] + x_cat_ohe)).squeeze(-1)\n",
        "\n",
        "    elif isinstance(model, FTTransformer):\n",
        "        return model(batch[\"x_cont\"], batch.get(\"x_cat\")).squeeze(-1)\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown model type: {type(model)}\")\n",
        "\n",
        "\n",
        "loss_fn = (\n",
        "    F.binary_cross_entropy_with_logits\n",
        "    if task_type == \"binclass\"\n",
        "    else F.cross_entropy\n",
        "    if task_type == \"multiclass\"\n",
        "    else F.mse_loss\n",
        ")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(part: str) -> float:\n",
        "    model.eval()\n",
        "\n",
        "    eval_batch_size = 8096\n",
        "    y_pred = (\n",
        "        torch.cat(\n",
        "            [\n",
        "                apply_model(batch)\n",
        "                for batch in delu.iter_batches(data[part], eval_batch_size)\n",
        "            ]\n",
        "        )\n",
        "        .cpu()\n",
        "        .numpy()\n",
        "    )\n",
        "    y_true = data[part][\"y\"].cpu().numpy()\n",
        "\n",
        "    if task_type == \"binclass\":\n",
        "        y_pred = np.round(scipy.special.expit(y_pred))\n",
        "        score = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "    elif task_type == \"multiclass\":\n",
        "        y_pred = y_pred.argmax(1)\n",
        "        score = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "    else:\n",
        "        assert task_type == \"regression\"\n",
        "        score = -(sklearn.metrics.mean_squared_error(y_true, y_pred) ** 0.5 * Y_std)\n",
        "    return score  # The higher -- the better.\n",
        "\n",
        "\n",
        "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIZUjDgqPLnF",
        "outputId": "e73fde92-1221-4743-fdbd-f24c2718248d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: CPU\n",
            "----------------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.6049 (test) -0.6037 [time] 0:00:19.696423\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5908 (test) -0.5899 [time] 0:00:40.154628\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5632 (test) -0.5595 [time] 0:01:00.121366\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5590 (test) -0.5543 [time] 0:01:20.256528\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5647 (test) -0.5568 [time] 0:01:41.215181\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5424 (test) -0.5349 [time] 0:02:00.896521\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5411 (test) -0.5380 [time] 0:02:22.254213\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5326 (test) -0.5277 [time] 0:02:42.299034\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5448 (test) -0.5407 [time] 0:03:02.365735\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5143 (test) -0.5078 [time] 0:03:22.965901\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5191 (test) -0.5164 [time] 0:03:42.572620\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5246 (test) -0.5206 [time] 0:04:03.211719\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5108 (test) -0.5045 [time] 0:04:22.904591\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5085 (test) -0.5033 [time] 0:04:43.368542\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5124 (test) -0.5100 [time] 0:05:03.759935\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5035 (test) -0.5038 [time] 0:05:23.410906\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4982 (test) -0.4947 [time] 0:05:43.900751\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5109 (test) -0.5109 [time] 0:06:03.411666\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5027 (test) -0.4988 [time] 0:06:24.006510\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4994 (test) -0.4993 [time] 0:06:44.003397\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5001 (test) -0.4983 [time] 0:07:04.161089\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5126 (test) -0.5047 [time] 0:07:24.797132\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4901 (test) -0.4901 [time] 0:07:44.372293\n",
            "ğŸŒ¸ New best epoch! ğŸŒ¸\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4985 (test) -0.4934 [time] 0:08:04.780578\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4975 (test) -0.4945 [time] 0:08:24.524235\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5022 (test) -0.4940 [time] 0:08:45.072875\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4974 (test) -0.4962 [time] 0:09:05.380834\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5071 (test) -0.5015 [time] 0:09:25.196836\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4924 (test) -0.4854 [time] 0:09:45.574674\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4913 (test) -0.4899 [time] 0:10:05.267317\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4921 (test) -0.4866 [time] 0:10:26.029535\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:15<00:00,  3.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4925 (test) -0.4957 [time] 0:10:45.952530\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.5023 (test) -0.5012 [time] 0:11:06.224796\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4934 (test) -0.4904 [time] 0:11:28.221136\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:20<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4911 (test) -0.4861 [time] 0:11:53.392069\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4930 (test) -0.4871 [time] 0:12:13.104367\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4915 (test) -0.4860 [time] 0:12:33.824203\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:16<00:00,  3.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4904 (test) -0.4884 [time] 0:12:53.794990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:17<00:00,  3.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(val) -0.4937 (test) -0.4932 [time] 0:13:14.777185\n",
            "\n",
            "\n",
            "Result:\n",
            "{'val': -0.49009838061302624, 'test': -0.4901484418138897, 'epoch': 22}\n"
          ]
        }
      ],
      "source": [
        "# For demonstration purposes (fast training and bad performance),\n",
        "# one can set smaller values:\n",
        "# n_epochs = 20\n",
        "# patience = 2\n",
        "n_epochs = 1_000_000_000\n",
        "patience = 16\n",
        "\n",
        "batch_size = 256\n",
        "epoch_size = math.ceil(len(train_idx) / batch_size)\n",
        "timer = delu.tools.Timer()\n",
        "early_stopping = delu.tools.EarlyStopping(patience, mode=\"max\")\n",
        "best = {\n",
        "    \"val\": -math.inf,\n",
        "    \"test\": -math.inf,\n",
        "    \"epoch\": -1,\n",
        "}\n",
        "\n",
        "print(f\"Device: {device.type.upper()}\")\n",
        "print(\"-\" * 88 + \"\\n\")\n",
        "timer.run()\n",
        "for epoch in range(n_epochs):\n",
        "    for batch in tqdm(\n",
        "        delu.iter_batches(data[\"train\"], batch_size, shuffle=True),\n",
        "        desc=f\"Epoch {epoch}\",\n",
        "        total=epoch_size,\n",
        "    ):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(apply_model(batch), batch[\"y\"])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    val_score = evaluate(\"val\")\n",
        "    test_score = evaluate(\"test\")\n",
        "    print(f\"(val) {val_score:.4f} (test) {test_score:.4f} [time] {timer}\")\n",
        "\n",
        "    early_stopping.update(val_score)\n",
        "    if early_stopping.should_stop():\n",
        "        break\n",
        "\n",
        "    if val_score > best[\"val\"]:\n",
        "        print(\"ğŸŒ¸ New best epoch! ğŸŒ¸\")\n",
        "        best = {\"val\": val_score, \"test\": test_score, \"epoch\": epoch}\n",
        "    print()\n",
        "\n",
        "print(\"\\n\\nResult:\")\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WnkhHDPfPLnG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}